{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Комбинирование нескольких MCP-серверов\n",
    "\n",
    "FastMCP позволяет объединять несколько независимых серверов в один через метод `import_server()`.\n",
    "\n",
    "Это позволяет строить модульные системы, где каждый сервер отвечает за свою область, но все они доступны через единую точку входа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "## Шаг 1: Импорты и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from fastmcp import Client\n",
    "from langchain.agents import create_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BASE_MODEL = os.getenv(\"BASE_MODEL\") or \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {},
   "source": [
    "## Шаг 2: Структура комбинированного сервера\n",
    "\n",
    "У нас есть три файла:\n",
    "\n",
    "- `math_server.py` - инструменты для математики (calculate, factorial)\n",
    "- `text_server.py` - инструменты для текста (count_words, reverse_text, to_uppercase)\n",
    "- `server_combined.py` - главный сервер, который импортирует оба через `mcp.import_server()`\n",
    "\n",
    "Каждый сервер независим и может использоваться отдельно, но в комбинированном они работают вместе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {},
   "source": [
    "## Шаг 3: Как работает import_server()\n",
    "\n",
    "В `server_combined.py` есть функция setup():\n",
    "\n",
    "```python\n",
    "async def setup():\n",
    "    await mcp.import_server(math_server)\n",
    "    await mcp.import_server(text_server)\n",
    "```\n",
    "\n",
    "Эта функция берет все инструменты из импортированных серверов и переносит их в главный сервер."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {},
   "source": [
    "## Шаг 4: Подключение и использование\n",
    "\n",
    "Для агента все инструменты выглядят как единый набор возможностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    server_script = Path(\"server_combined.py\")\n",
    "\n",
    "    async with Client(str(server_script)) as client:\n",
    "        print(\"Available tools from combined server:\")\n",
    "        tools_list = await client.list_tools()\n",
    "        for tool in tools_list:\n",
    "            print(f\"  - {tool.name}\")\n",
    "\n",
    "        tools = await load_mcp_tools(client.session)\n",
    "\n",
    "        llm = ChatOpenAI(model=BASE_MODEL, temperature=0)\n",
    "\n",
    "        agent = create_agent(llm, tools)\n",
    "\n",
    "        test_pdf = Path(\"../../../data/test.pdf\")\n",
    "\n",
    "        response = await agent.ainvoke(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    (\n",
    "                        \"user\",\n",
    "                        f\"\"\"Perform a multi-step analysis:\n",
    "1. Get statistics about the document at {test_pdf}\n",
    "2. Calculate the factorial of the word count\n",
    "3. Reverse the document name\n",
    "\n",
    "Please execute all these tasks and present the results clearly.\"\"\",\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(\"\\nAgent response:\")\n",
    "        for message in response[\"messages\"]:\n",
    "            if (\n",
    "                message.type == \"ai\"\n",
    "                and hasattr(message, \"content\")\n",
    "                and message.content\n",
    "            ):\n",
    "                print(f\"\\n{message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {},
   "source": [
    "## Шаг 5: Запуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {},
   "source": [
    "## Преимущества модульной архитектуры\n",
    "\n",
    "- **Переиспользуемость**: базовые серверы можно использовать в разных проектах\n",
    "- **Тестируемость**: каждый сервер тестируется отдельно\n",
    "- **Поддерживаемость**: изменения в одном сервере не затрагивают другие\n",
    "- **Гибкость**: можно комбинировать серверы в разных конфигурациях\n",
    "\n",
    "Такой подход позволяет строить библиотеку переиспользуемых компонентов."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
