{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Часть 2: Создание собственного MCP-сервера\n",
    "\n",
    "В этом примере мы создадим собственный MCP-сервер с использованием FastMCP и подключим его к агенту через STDIO транспорт.\n",
    "\n",
    "MCP решает проблемы обычного tool calling через стандартизацию и переиспользуемость."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "## Шаг 1: Импорты и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from fastmcp import Client\n",
    "from langchain.agents import create_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BASE_MODEL = os.getenv(\"BASE_MODEL\") or \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {},
   "source": [
    "## Шаг 2: Структура MCP-сервера\n",
    "\n",
    "Наш сервер находится в файле `server_stdio.py`. Он использует FastMCP и предоставляет два инструмента:\n",
    "\n",
    "- `convert_document` - конвертирует документы в markdown\n",
    "- `analyze_document` - возвращает статистику о документе\n",
    "\n",
    "Сервер запускается как отдельный процесс и общается через STDIO транспорт."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {},
   "source": [
    "## Шаг 3: Подключение к серверу\n",
    "\n",
    "Создаем клиент, который подключается к нашему серверу через STDIO.\n",
    "Сервер автоматически предоставляет список своих инструментов через `tools/list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    server_script = Path(\"server_stdio.py\")\n",
    "\n",
    "    async with Client(str(server_script)) as client:\n",
    "        print(\"Available tools:\")\n",
    "        tools_list = await client.list_tools()\n",
    "        for tool in tools_list:\n",
    "            print(f\"  - {tool.name}\")\n",
    "\n",
    "        tools = await load_mcp_tools(client.session)\n",
    "\n",
    "        llm = ChatOpenAI(model=BASE_MODEL, temperature=0)\n",
    "\n",
    "        agent = create_agent(llm, tools)\n",
    "\n",
    "        test_pdf = Path(\"../../data/test.pdf\")\n",
    "\n",
    "        response = await agent.ainvoke(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    (\n",
    "                        \"user\",\n",
    "                        f\"Analyze the document structure at {test_pdf} and create laconic summary of the text.\",\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(\"Agent response:\")\n",
    "        for message in response[\"messages\"]:\n",
    "            if (\n",
    "                message.type == \"ai\"\n",
    "                and hasattr(message, \"content\")\n",
    "                and message.content\n",
    "            ):\n",
    "                print(f\"\\n{message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "## Шаг 4: Запуск примера\n",
    "\n",
    "Выполним асинхронную функцию main для взаимодействия с сервером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {},
   "source": [
    "## Преимущества MCP\n",
    "\n",
    "По сравнению с обычным tool calling, MCP предоставляет:\n",
    "\n",
    "- **Стандартизацию**: один сервер работает с любыми совместимыми клиентами\n",
    "- **Автоматическое обнаружение**: клиент узнает о возможностях через `tools/list`\n",
    "- **Переиспользуемость**: сервер можно использовать в разных проектах без изменений\n",
    "- **Изоляцию**: сервер работает в отдельном процессе\n",
    "- **Масштабируемость**: легко добавлять новые инструменты и развертывать удаленно"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
