{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Часть 1: Основы Tool Calling для LLM-агентов\n",
    "\n",
    "В этой части мастер-класса мы разберем, как языковые модели могут вызывать внешние функции и взаимодействовать с окружением. Вы узнаете о механизме tool calling на фундаментальном уровне."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "## Структурированный вывод - основа tool calling\n",
    "\n",
    "Прежде чем разбирать работу с инструментами, важно понять ключевую концепцию - структурированный вывод.\n",
    "\n",
    "По умолчанию языковая модель возвращает обычный текст, который удобен для чтения человеком, но плох для программной обработки. Структурированный вывод - это когда модель возвращает данные в строго определенном формате, например JSON.\n",
    "\n",
    "Именно это позволяет автоматически парсить ответ модели, извлекать нужные поля и на их основе принимать решения - например, какую функцию вызвать и с какими параметрами. Без структурированного вывода механизм tool calling просто не смог бы работать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {},
   "source": [
    "## Три этапа работы с инструментами\n",
    "\n",
    "Работу с инструментами можно разбить на три ключевых этапа:\n",
    "\n",
    "1. **Определение инструмента** - описание возможностей\n",
    "2. **Вызов инструмента** - выбор и вызов модель\n",
    "3. **Возврат результата** - обработка и передача данных обратно модели\n",
    "\n",
    "На каждом из этих этапов используется структурированный вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {},
   "source": [
    "## Этап 1: Определение инструмента\n",
    "\n",
    "Инструмент описывается в виде JSON-схемы с ключевыми параметрами:\n",
    "\n",
    "- **name** - имя инструмента\n",
    "- **description** - описание работы (зачем использовать, в каких ситуациях)\n",
    "- **input_schema** - требуемые и опциональные параметры инструмента\n",
    "\n",
    "LLM на этапе fine-tuning обучалась вызову инструментов по заданному протоколу. Модель \"понимает\", что когда она видит такое описание, она может использовать этот инструмент для решения задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {},
   "source": [
    "Пример определения инструмента в JSON:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"get_weather\",\n",
    "  \"description\": \"Получает текущую погоду для указанного города\",\n",
    "  \"input_schema\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"city\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Название города\"\n",
    "      },\n",
    "      \"units\": {\n",
    "        \"type\": \"string\",\n",
    "        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "        \"description\": \"Единицы измерения температуры\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"city\"]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {},
   "source": [
    "## Этап 2: Вызов инструмента\n",
    "\n",
    "Модель возвращает JSON с названием функции и параметрами. Важно понимать: сам по себе JSON от модели не вызывает никакую функцию. Это просто структурированный текст.\n",
    "\n",
    "Нужен отдельный интерпретатор, который:\n",
    "1. Распарсит JSON от модели\n",
    "2. Найдет соответствующую Python-функцию\n",
    "3. Подставит параметры\n",
    "4. Выполнит функцию\n",
    "5. Вернет результат\n",
    "\n",
    "Хорошая новость: вам не нужно писать интерпретатор самостоятельно. Агентские фреймворки (LangChain, LangGraph, Pydantic AI) предоставляют готовый функционал."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "Пример полного цикла:\n",
    "\n",
    "```python\n",
    "# 1. Модель возвращает структурированный вывод\n",
    "model_response = {\n",
    "    \"tool_use\": {\n",
    "        \"id\": \"call_123\",\n",
    "        \"name\": \"get_weather\",\n",
    "        \"input\": {\"city\": \"Москва\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. Функция-инструмент\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"Температура в {city}: +5°C, облачно\"\n",
    "\n",
    "# 3. Интерпретатор вызывает функцию\n",
    "result = get_weather(**model_response[\"tool_use\"][\"input\"])\n",
    "\n",
    "# 4. Результат отправляется обратно модели\n",
    "tool_result = {\n",
    "    \"tool_result\": {\n",
    "        \"call_id\": \"call_123\",\n",
    "        \"content\": result\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {},
   "source": [
    "## Этап 3: Возврат результата\n",
    "\n",
    "Python-функция может вернуть простой текст, JSON или сложные объекты. Рекомендуется возвращать структурированные данные (JSON), так модели проще их обрабатывать.\n",
    "\n",
    "Модель получает результат и может:\n",
    "- Вызвать еще один инструмент\n",
    "- Вернуть окончательный ответ пользователю\n",
    "- Продолжить до достижения максимального количества итераций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {},
   "source": [
    "## Практический пример с LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {},
   "source": [
    "### Шаг 1: Импорты и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from markitdown import MarkItDown\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "BASE_MODEL = os.getenv(\"BASE_MODEL\") or \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {},
   "source": [
    "### Шаг 2: Создание инструмента\n",
    "\n",
    "Используем декоратор `@tool` из LangChain. Под капотом LangChain создает JSON-описание функции с параметрами и типами, которое передается модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MarkItDown()\n",
    "\n",
    "@tool\n",
    "def convert_to_markdown(file_path: str) -> str:\n",
    "    \"\"\"Extract text information from a document file into markdown format.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to document file (PDF, DOCX, XLSX, PPTX)\n",
    "\n",
    "    Returns:\n",
    "        Converted text content in Markdown format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        expanded_path = os.path.expanduser(file_path)\n",
    "        result = md.convert(expanded_path)\n",
    "        return result.text_content\n",
    "    except Exception as e:\n",
    "        return f\"ошибка конвертации: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iLit",
   "metadata": {},
   "source": [
    "### Шаг 3: Создание агента\n",
    "\n",
    "Агент получает список инструментов и может выбирать, какой из них использовать для решения задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [convert_to_markdown]\n",
    "\n",
    "llm = ChatOpenAI(model=BASE_MODEL, temperature=0)\n",
    "\n",
    "graph = create_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ROlb",
   "metadata": {},
   "source": [
    "### Шаг 4: Запуск агента\n",
    "\n",
    "Даем агенту задачу проанализировать документ. Агент:\n",
    "1. Видит описание инструмента `convert_to_markdown`\n",
    "2. Решает, что нужно вызвать этот инструмент\n",
    "3. Возвращает структурированный JSON с названием функции и параметрами\n",
    "4. LangChain вызывает функцию и передает результат обратно модели\n",
    "5. Модель формирует финальный ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pdf = Path(\"../../data/test.pdf\")\n",
    "\n",
    "result = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                f\"Analyze the document at {test_pdf} and tell me what it contains. Create an table .md .\",\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Result:\")\n",
    "for message in result[\"messages\"]:\n",
    "    if hasattr(message, \"content\") and message.content:\n",
    "        print(f\"{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TqIu",
   "metadata": {},
   "source": [
    "## Ограничения текущего подхода\n",
    "\n",
    "При работе с инструментами напрямую (без стандартизации) возникают проблемы:\n",
    "\n",
    "**1. Отсутствие переиспользуемости**\n",
    "Инструмент, написанный для одной модели или фреймворка, не работает с другими без переписывания.\n",
    "\n",
    "**2. Нет стандарта обнаружения**\n",
    "Каждый раз нужно вручную регистрировать инструменты и описывать их в правильном формате.\n",
    "\n",
    "**3. Проблемы с безопасностью**\n",
    "Нет встроенных механизмов для валидации параметров, контроля доступа, аудита вызовов и изоляции между инструментами.\n",
    "\n",
    "**4. Сложность масштабирования**\n",
    "При росте количества инструментов сложно управлять их описаниями, обеспечивать консистентность, версионировать изменения и тестировать взаимодействия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {},
   "source": [
    "## Что дальше?\n",
    "\n",
    "Механизм tool calling предоставляет языковым моделям большие возможности по работе с окружением, но подход с \"ручным\" определением инструментов имеет серьезные ограничения.\n",
    "\n",
    "В следующей части мы познакомимся с **Model Context Protocol (MCP)** - открытым стандартом, который решает все перечисленные проблемы и предоставляет унифицированный способ работы с инструментами, ресурсами и промптами для LLM-агентов.\n",
    "\n",
    "MCP использует те же три этапа, но добавляет:\n",
    "- Стандартизированный протокол обмена сообщениями\n",
    "- Автоматическое обнаружение возможностей\n",
    "- Встроенную валидацию и безопасность\n",
    "- Возможность переиспользования инструментов между проектами"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
